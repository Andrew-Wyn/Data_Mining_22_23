{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "296683c3",
   "metadata": {},
   "source": [
    "# Task 4: XAI - TABNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b287a7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 13:02:20.173898: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import tabnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7f3edc",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1607f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_masks(model):\n",
    "    for mask in model.tabnet.feature_selection_masks:\n",
    "        fig, ax = plt.subplots(figsize=(5, 20))\n",
    "        ax.imshow(mask[0])\n",
    "        plt.xticks(range(len(numerical_features)), numerical_features, rotation=\"vertical\") \n",
    "        plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 20))\n",
    "    ax.imshow(model.tabnet.aggregate_feature_selection_mask[0])\n",
    "    plt.xticks(range(len(numerical_features)), numerical_features, rotation=\"vertical\") \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "014cfdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_averaged_masks(model):\n",
    "    for mask in model.tabnet.feature_selection_masks:\n",
    "        fig, ax = plt.subplots(figsize=(5, 10))\n",
    "        avg = np.mean(mask[0], axis=0)\n",
    "        ax.imshow([avg/np.sum(avg)])\n",
    "        plt.xticks(range(len(numerical_features)), numerical_features, rotation=\"vertical\")\n",
    "        plt.yticks([])\n",
    "        plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 10))\n",
    "    avg = np.mean(model.tabnet.aggregate_feature_selection_mask[0], axis=0)\n",
    "    ax.imshow([np.array(avg)/np.sum(avg)])\n",
    "    plt.xticks(range(len(numerical_features)), numerical_features, rotation=\"vertical\")\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3939fd04",
   "metadata": {},
   "source": [
    "## Get Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7720778",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"dataset/cleaned_user_profiles.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65abcf70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lang</th>\n",
       "      <th>bot</th>\n",
       "      <th>created_at</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>avg_length</th>\n",
       "      <th>avg_special_chars</th>\n",
       "      <th>urls_ratio</th>\n",
       "      <th>mentions_ratio</th>\n",
       "      <th>hashtags_ratio</th>\n",
       "      <th>reply_count_mean</th>\n",
       "      <th>reply_count_std</th>\n",
       "      <th>favorite_count_mean</th>\n",
       "      <th>favorite_count_std</th>\n",
       "      <th>favorite_count_entropy</th>\n",
       "      <th>retweet_count_mean</th>\n",
       "      <th>retweet_count_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2353593986</th>\n",
       "      <td>Lamonica Raborn</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-02-22 18:00:42</td>\n",
       "      <td>76</td>\n",
       "      <td>62.340909</td>\n",
       "      <td>14.015152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.098485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037879</td>\n",
       "      <td>0.190903</td>\n",
       "      <td>0.232481</td>\n",
       "      <td>0.037879</td>\n",
       "      <td>0.190903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358850842</th>\n",
       "      <td>Lourie Botton</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-26 03:02:32</td>\n",
       "      <td>54</td>\n",
       "      <td>69.082645</td>\n",
       "      <td>15.041322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338843</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049587</td>\n",
       "      <td>0.217090</td>\n",
       "      <td>0.284639</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>0.155495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137959629</th>\n",
       "      <td>Dadan Syarifudin</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-04-30 07:09:56</td>\n",
       "      <td>53</td>\n",
       "      <td>65.340909</td>\n",
       "      <td>14.694444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466124818</th>\n",
       "      <td>Carletto Focia</td>\n",
       "      <td>it</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-18 02:49:18</td>\n",
       "      <td>50</td>\n",
       "      <td>86.944871</td>\n",
       "      <td>18.689463</td>\n",
       "      <td>0.022331</td>\n",
       "      <td>0.006281</td>\n",
       "      <td>0.072575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165387</td>\n",
       "      <td>0.530838</td>\n",
       "      <td>0.669155</td>\n",
       "      <td>0.826239</td>\n",
       "      <td>13.034008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571493866</th>\n",
       "      <td>MBK Ebook</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-18 19:30:21</td>\n",
       "      <td>7085</td>\n",
       "      <td>72.311246</td>\n",
       "      <td>14.582073</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.506461</td>\n",
       "      <td>0.118229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056365</td>\n",
       "      <td>0.243387</td>\n",
       "      <td>0.317182</td>\n",
       "      <td>0.016772</td>\n",
       "      <td>0.142619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name lang  bot           created_at  statuses_count  \\\n",
       "2353593986   Lamonica Raborn   en    1  2019-02-22 18:00:42              76   \n",
       "2358850842     Lourie Botton   en    0  2019-02-26 03:02:32              54   \n",
       "137959629   Dadan Syarifudin   en    1  2015-04-30 07:09:56              53   \n",
       "466124818     Carletto Focia   it    1  2017-01-18 02:49:18              50   \n",
       "2571493866         MBK Ebook   en    0  2019-06-18 19:30:21            7085   \n",
       "\n",
       "            avg_length  avg_special_chars  urls_ratio  mentions_ratio  \\\n",
       "2353593986   62.340909          14.015152    0.000000        0.272727   \n",
       "2358850842   69.082645          15.041322    0.000000        0.338843   \n",
       "137959629    65.340909          14.694444    0.000000        0.000000   \n",
       "466124818    86.944871          18.689463    0.022331        0.006281   \n",
       "2571493866   72.311246          14.582073    0.000825        0.506461   \n",
       "\n",
       "            hashtags_ratio  reply_count_mean  reply_count_std  \\\n",
       "2353593986        0.098485               0.0              0.0   \n",
       "2358850842        0.024793               0.0              0.0   \n",
       "137959629         0.000000               0.0              0.0   \n",
       "466124818         0.072575               0.0              0.0   \n",
       "2571493866        0.118229               0.0              0.0   \n",
       "\n",
       "            favorite_count_mean  favorite_count_std  favorite_count_entropy  \\\n",
       "2353593986             0.037879            0.190903                0.232481   \n",
       "2358850842             0.049587            0.217090                0.284639   \n",
       "137959629              0.000000            0.000000                0.000000   \n",
       "466124818              0.165387            0.530838                0.669155   \n",
       "2571493866             0.056365            0.243387                0.317182   \n",
       "\n",
       "            retweet_count_mean  retweet_count_std  \n",
       "2353593986            0.037879           0.190903  \n",
       "2358850842            0.024793           0.155495  \n",
       "137959629             0.000000           0.000000  \n",
       "466124818             0.826239          13.034008  \n",
       "2571493866            0.016772           0.142619  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "281970f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data.pop('bot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb89193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datetime to timestamp to permit classification\n",
    "data[\"created_at\"] = pd.to_datetime(data.created_at).values.astype(np.int64) // 10 ** 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f996d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_features = [\"lang\", \"bot\", \"created_at\", \"name\"]\n",
    "categorical_features = [\"lang\", \"name\"]\n",
    "\n",
    "# remove categorical variables\n",
    "numerical_features = list(data.columns).copy()\n",
    "\n",
    "for feat in categorical_features:\n",
    "    numerical_features.remove(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4598a340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['created_at',\n",
       " 'statuses_count',\n",
       " 'avg_length',\n",
       " 'avg_special_chars',\n",
       " 'urls_ratio',\n",
       " 'mentions_ratio',\n",
       " 'hashtags_ratio',\n",
       " 'reply_count_mean',\n",
       " 'reply_count_std',\n",
       " 'favorite_count_mean',\n",
       " 'favorite_count_std',\n",
       " 'favorite_count_entropy',\n",
       " 'retweet_count_mean',\n",
       " 'retweet_count_std']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2b88eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data = data[numerical_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0aa2be93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>avg_length</th>\n",
       "      <th>avg_special_chars</th>\n",
       "      <th>urls_ratio</th>\n",
       "      <th>mentions_ratio</th>\n",
       "      <th>hashtags_ratio</th>\n",
       "      <th>reply_count_mean</th>\n",
       "      <th>reply_count_std</th>\n",
       "      <th>favorite_count_mean</th>\n",
       "      <th>favorite_count_std</th>\n",
       "      <th>favorite_count_entropy</th>\n",
       "      <th>retweet_count_mean</th>\n",
       "      <th>retweet_count_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2353593986</th>\n",
       "      <td>1550858442</td>\n",
       "      <td>76</td>\n",
       "      <td>62.340909</td>\n",
       "      <td>14.015152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.098485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037879</td>\n",
       "      <td>0.190903</td>\n",
       "      <td>0.232481</td>\n",
       "      <td>0.037879</td>\n",
       "      <td>0.190903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358850842</th>\n",
       "      <td>1551150152</td>\n",
       "      <td>54</td>\n",
       "      <td>69.082645</td>\n",
       "      <td>15.041322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338843</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049587</td>\n",
       "      <td>0.217090</td>\n",
       "      <td>0.284639</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>0.155495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137959629</th>\n",
       "      <td>1430377796</td>\n",
       "      <td>53</td>\n",
       "      <td>65.340909</td>\n",
       "      <td>14.694444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466124818</th>\n",
       "      <td>1484707758</td>\n",
       "      <td>50</td>\n",
       "      <td>86.944871</td>\n",
       "      <td>18.689463</td>\n",
       "      <td>0.022331</td>\n",
       "      <td>0.006281</td>\n",
       "      <td>0.072575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165387</td>\n",
       "      <td>0.530838</td>\n",
       "      <td>0.669155</td>\n",
       "      <td>0.826239</td>\n",
       "      <td>13.034008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571493866</th>\n",
       "      <td>1560886221</td>\n",
       "      <td>7085</td>\n",
       "      <td>72.311246</td>\n",
       "      <td>14.582073</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.506461</td>\n",
       "      <td>0.118229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056365</td>\n",
       "      <td>0.243387</td>\n",
       "      <td>0.317182</td>\n",
       "      <td>0.016772</td>\n",
       "      <td>0.142619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at  statuses_count  avg_length  avg_special_chars  \\\n",
       "2353593986  1550858442              76   62.340909          14.015152   \n",
       "2358850842  1551150152              54   69.082645          15.041322   \n",
       "137959629   1430377796              53   65.340909          14.694444   \n",
       "466124818   1484707758              50   86.944871          18.689463   \n",
       "2571493866  1560886221            7085   72.311246          14.582073   \n",
       "\n",
       "            urls_ratio  mentions_ratio  hashtags_ratio  reply_count_mean  \\\n",
       "2353593986    0.000000        0.272727        0.098485               0.0   \n",
       "2358850842    0.000000        0.338843        0.024793               0.0   \n",
       "137959629     0.000000        0.000000        0.000000               0.0   \n",
       "466124818     0.022331        0.006281        0.072575               0.0   \n",
       "2571493866    0.000825        0.506461        0.118229               0.0   \n",
       "\n",
       "            reply_count_std  favorite_count_mean  favorite_count_std  \\\n",
       "2353593986              0.0             0.037879            0.190903   \n",
       "2358850842              0.0             0.049587            0.217090   \n",
       "137959629               0.0             0.000000            0.000000   \n",
       "466124818               0.0             0.165387            0.530838   \n",
       "2571493866              0.0             0.056365            0.243387   \n",
       "\n",
       "            favorite_count_entropy  retweet_count_mean  retweet_count_std  \n",
       "2353593986                0.232481            0.037879           0.190903  \n",
       "2358850842                0.284639            0.024793           0.155495  \n",
       "137959629                 0.000000            0.000000           0.000000  \n",
       "466124818                 0.669155            0.826239          13.034008  \n",
       "2571493866                0.317182            0.016772           0.142619  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "977fbdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2353593986    1\n",
       "2358850842    0\n",
       "137959629     1\n",
       "466124818     1\n",
       "2571493866    0\n",
       "Name: bot, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a90bf914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 13:02:23.199580: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "numerical_dataset = tf.data.Dataset.from_tensor_slices((numerical_data, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "461f24e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data, target):\n",
    "    data = tf.unstack(data)\n",
    "    \n",
    "    x = dict(zip(numerical_features, data))\n",
    "    y = tf.one_hot(target, 2)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f78b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_size = int(data.shape[0] / 100 * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e7494ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_full = numerical_dataset.shuffle(data.shape[0], seed=0)\n",
    "# ds_full = numerical_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5c4efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_full.take(train_size)\n",
    "ds_train = ds_train.map(transform)\n",
    "ds_train = ds_train.batch(BATCH_SIZE)\n",
    "ds_test = ds_full.skip(train_size)\n",
    "ds_test = ds_test.map(transform)\n",
    "ds_test = ds_test.batch(BATCH_SIZE)\n",
    "\n",
    "feature_columns = []\n",
    "for col_name in numerical_features:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(col_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ba8ce78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='created_at', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='statuses_count', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='avg_length', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='avg_special_chars', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='urls_ratio', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='mentions_ratio', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='hashtags_ratio', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='reply_count_mean', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='reply_count_std', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='favorite_count_mean', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='favorite_count_std', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='favorite_count_entropy', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='retweet_count_mean', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='retweet_count_std', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e29ac8",
   "metadata": {},
   "source": [
    "## Define and Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f10c524a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TabNet]: 64 features will be used for decision steps.\n"
     ]
    }
   ],
   "source": [
    "# Group Norm does better for small datasets\n",
    "model = tabnet.TabNetClassifier(feature_columns, num_classes=2,\n",
    "                                feature_dim=128, output_dim=64,\n",
    "                                num_decision_steps=12, relaxation_factor=1.5,\n",
    "                                sparsity_coefficient=0., batch_momentum=0.8,\n",
    "                                virtual_batch_size=None, norm_type=\"batch\")\n",
    "                                \n",
    "\n",
    "lr = tf.keras.optimizers.schedules.ExponentialDecay(0.0012, decay_steps=100, decay_rate=0.9, staircase=False)\n",
    "optimizer = tf.keras.optimizers.Adam(lr)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce7d17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 24s 91ms/step - loss: 0.5839 - accuracy: 0.7435 - val_loss: 0.5213 - val_accuracy: 0.7564\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 0.5045 - accuracy: 0.7652 - val_loss: 0.4666 - val_accuracy: 0.7822\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 0.4784 - accuracy: 0.7808 - val_loss: 0.4789 - val_accuracy: 0.7602\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 0.4792 - accuracy: 0.7760 - val_loss: 0.4852 - val_accuracy: 0.7776\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 4s 58ms/step - loss: 0.4713 - accuracy: 0.7779 - val_loss: 0.4695 - val_accuracy: 0.7871\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 4s 58ms/step - loss: 0.4674 - accuracy: 0.7801 - val_loss: 0.4701 - val_accuracy: 0.7857\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 4s 58ms/step - loss: 0.4572 - accuracy: 0.7896 - val_loss: 0.4741 - val_accuracy: 0.7787\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 0.4580 - accuracy: 0.7875 - val_loss: 0.4583 - val_accuracy: 0.7845\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 4s 59ms/step - loss: 0.4470 - accuracy: 0.7877 - val_loss: 0.4439 - val_accuracy: 0.8042\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 4s 59ms/step - loss: 0.4479 - accuracy: 0.7852 - val_loss: 0.4640 - val_accuracy: 0.7854\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 4s 58ms/step - loss: 0.4574 - accuracy: 0.7839 - val_loss: 0.4433 - val_accuracy: 0.7990\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 4s 63ms/step - loss: 0.4696 - accuracy: 0.7804 - val_loss: 0.4674 - val_accuracy: 0.7886\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 4s 60ms/step - loss: 0.4490 - accuracy: 0.7923 - val_loss: 0.4670 - val_accuracy: 0.7802\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 4s 59ms/step - loss: 0.4456 - accuracy: 0.7921 - val_loss: 0.4483 - val_accuracy: 0.7924\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 4s 59ms/step - loss: 0.4474 - accuracy: 0.7865 - val_loss: 0.4563 - val_accuracy: 0.7874\n",
      "Epoch 16/100\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.4482 - accuracy: 0.7845"
     ]
    }
   ],
   "source": [
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "\n",
    "model.fit(ds_train, epochs=100, validation_data=ds_test, callbacks=[early_stopping_callback])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e934d45",
   "metadata": {},
   "source": [
    "## Evaluation and plot the Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a730aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(ds_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9b4a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force eager execution mode to generate the masks\n",
    "x, y = next(iter(ds_train))\n",
    "\n",
    "_ = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70f67ea",
   "metadata": {},
   "source": [
    "### Explanations\n",
    "\n",
    "More yellow cells indicates more importance features for a certain sample.\n",
    "In the following we can see the masks generated by the TabNet algorithm. The last is the aggregation of the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d86fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_masks(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be933261",
   "metadata": {},
   "source": [
    "Report now the averaging of the masks over the different samples.\n",
    "\n",
    "We can see in the aggregation that the most important feature is the **favourite_count_entropy**, this is not consistent with the other results get from the other XAI methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1259d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_averaged_masks(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
